{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification_problem_hw2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ektaatomar/Identify-income-bracket-based-on-demographics/blob/master/Classification_problem_hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0RcUuzObMnwC",
        "colab_type": "code",
        "outputId": "d9ac3652-6011-4a47-a2d1-a1baf6cd4c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#read directly from the link\n",
        "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\")\n",
        "\n",
        "#data doesn't have column names in file \n",
        "df.columns= ['age',\n",
        "'workclass',\n",
        "'fnlwgt',\n",
        "'education',\n",
        "'education-num',\n",
        "'marital-status',\n",
        "'occupation',\n",
        "'relationship',\n",
        "'race',\n",
        "'sex',\n",
        "'capital-gain',\n",
        "'capital-loss',\n",
        "'hours-per-week',\n",
        "'native-country','income']\n",
        "\n",
        "#print(df.describe())\n",
        "\n",
        "count_class_0, count_class_1 = df.income.value_counts()\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "print(df.isnull().values.any())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   age          workclass  fnlwgt   education  education-num  \\\n",
            "0   50   Self-emp-not-inc   83311   Bachelors             13   \n",
            "1   38            Private  215646     HS-grad              9   \n",
            "2   53            Private  234721        11th              7   \n",
            "3   28            Private  338409   Bachelors             13   \n",
            "4   37            Private  284582     Masters             14   \n",
            "\n",
            "        marital-status          occupation    relationship    race      sex  \\\n",
            "0   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
            "1             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
            "2   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
            "3   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
            "4   Married-civ-spouse     Exec-managerial            Wife   White   Female   \n",
            "\n",
            "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
            "0             0             0              13   United-States   <=50K  \n",
            "1             0             0              40   United-States   <=50K  \n",
            "2             0             0              40   United-States   <=50K  \n",
            "3             0             0              40            Cuba   <=50K  \n",
            "4             0             0              40   United-States   <=50K  \n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CZDuLq7KqSqB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Part of a different approach. - In case we have to remove missing value or the see how much missing values are there for how many columns. We dont require it here as the models seem to work pretty good with label encoder."
      ]
    },
    {
      "metadata": {
        "id": "7Psq2e6AormZ",
        "colab_type": "code",
        "outputId": "dac99016-f8fa-4187-cfdc-3919ea256b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "#df.where(df['workclass']!='?')\n",
        "#df.info\n",
        "#is_2002 =  df[df['workclass'].str!=' ?']\n",
        "#print(is_2002)\n",
        "#df.astype(str)\n",
        "#print(df['native-country'].unique())\n",
        "#df_copy=df.where(df['workclass']==' ?')\n",
        "#print(df_copy)\n",
        "#df['age'].where(df['age'].astype(str)==' ?').count()\n",
        "#df['occupation'].where(df['occupation']==' ?').count()\n",
        "#df.where(df['native-country']==' ?')\n",
        "\n",
        "\n",
        "# Divide by class\n",
        "'''\n",
        "df_class_0 = df[df['income'] == ' <=50K']\n",
        "df_class_1 = df[df['income'] == ' >50K']\n",
        "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
        "df_test_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
        "\n",
        "print('Random over-sampling:')\n",
        "print(df_test_over.income.value_counts())\n",
        "\n",
        "df_test_over.income.value_counts().plot(kind='bar', title='Count (income)');'''\n",
        "\n",
        "\n",
        "'''df_variable = df[['age',\n",
        "'workclass',\n",
        "'fnlwgt',\n",
        "'education',\n",
        "'education-num',\n",
        "'marital-status',\n",
        "'occupation',\n",
        "'relationship',\n",
        "'race',\n",
        "'sex',\n",
        "'capital-gain',\n",
        "'capital-loss',\n",
        "'hours-per-week',\n",
        "'native-country']]'''\n",
        "\n",
        "#df_target=df[['income']]\n",
        "#print(df_target.head())\n",
        "\n",
        "\n",
        "#df_variable.describe()\n",
        "#imputed_matrix= KNN(k=3).fit_transform(df_variable)\n",
        "#imputed_df= pd.DataFrame(imputed_matrix, columns = df.columns)\n",
        "#imputed_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"df_variable = df[['age',\\n'workclass',\\n'fnlwgt',\\n'education',\\n'education-num',\\n'marital-status',\\n'occupation',\\n'relationship',\\n'race',\\n'sex',\\n'capital-gain',\\n'capital-loss',\\n'hours-per-week',\\n'native-country']]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "LoGAUPJHTrbr",
        "colab_type": "code",
        "outputId": "bf38caa8-10ad-43d3-8f32-c09f54f3b649",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "Lencoder= LabelEncoder()\n",
        "df=df.apply(Lencoder.fit_transform)\n",
        "df_target=df[['income']]\n",
        "df_features = df[['age',\n",
        "'workclass',\n",
        "'fnlwgt',\n",
        "'education',\n",
        "'education-num',\n",
        "'marital-status',\n",
        "'occupation',\n",
        "'relationship',\n",
        "'race',\n",
        "'sex',\n",
        "'capital-gain',\n",
        "'capital-loss',\n",
        "'hours-per-week',\n",
        "'native-country']]\n",
        "print(df_target.head())\n",
        "\n",
        "#df_features = pd.get_dummies(df_variable, drop_first = True) \n",
        "#df_features=df_variable.apply(Lencoder.fit_transform)\n",
        "#df_features.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   income\n",
            "0       0\n",
            "1       0\n",
            "2       0\n",
            "3       0\n",
            "4       0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i_1W7-nlghAT",
        "colab_type": "code",
        "outputId": "398fe4d5-6d36-4019-c5e1-f4611d37a45d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score,precision_score, recall_score, f1_score, classification_report, auc,precision_recall_curve\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(df_features,df_target, test_size = 0.20, random_state = 0)\n",
        "tree=DecisionTreeClassifier(criterion='entropy', max_depth=10)\n",
        "tree.fit(x_train,y_train)\n",
        "predictions=tree.predict(x_test)\n",
        "print(\"DecisionTreeClassifier \\n\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(tree.score(x_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(tree.score(x_test, y_test)))\n",
        "print(\"Feature importances:\\n{}\".format(tree.feature_importances_))\n",
        "print(\"The confusion matrix is:\\n\", confusion_matrix(y_test,predictions))\n",
        "labels = ['Class 0', 'Class 1']\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(confusion_matrix(y_test,predictions), cmap=plt.cm.Blues)\n",
        "fig.colorbar(cax)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Expected')\n",
        "plt.show()\n",
        "\n",
        "print(\"Accuracy score: {:.3f}\".format(accuracy_score(y_test,predictions)))\n",
        "print(\"f1_score: {:.3f}\".format(f1_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"precision_score: {:.3f}\".format(precision_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"recall_score: {:.3f}\".format(recall_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"classification_report:\\n{}\".format(classification_report(y_test,predictions, target_names=['<=50k','>50k'])))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(y_test.shape)\n",
        "#new_data=y_test['income'].reshape(6512,)\n",
        "#print(new_data)\n",
        "#print(new_data.shape)\n",
        "#print(predictions.shape)\n",
        "\n",
        "FPR, TPR, thresholds = precision_recall_curve(y_test, predictions, pos_label =1)\n",
        "print(\"AUC = \",auc(FPR, TPR))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier \n",
            "\n",
            "Accuracy on training set: 0.867\n",
            "Accuracy on test set: 0.859\n",
            "Feature importances:\n",
            "[0.06490976 0.00827105 0.01739708 0.00040847 0.16196962 0.00163389\n",
            " 0.02470986 0.38404068 0.00339902 0.00269081 0.21639281 0.06284166\n",
            " 0.04742714 0.00390815]\n",
            "The confusion matrix is:\n",
            " [[4598  359]\n",
            " [ 556  999]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbIAAAFYCAYAAAA2rHn4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEUv7f/pu/G3Du4eOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa0487accc0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.859\n",
            "f1_score: 0.856\n",
            "precision_score: 0.855\n",
            "recall_score: 0.859\n",
            "classification_report:\n",
            "             precision    recall  f1-score   support\n",
            "\n",
            "      <=50k       0.89      0.93      0.91      4957\n",
            "       >50k       0.74      0.64      0.69      1555\n",
            "\n",
            "avg / total       0.85      0.86      0.86      6512\n",
            "\n",
            "(6512, 1)\n",
            "AUC =  0.49294268035815086\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "76U0wBkzpjIm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JxFYEyEjS0IX",
        "colab_type": "code",
        "outputId": "6fcc9197-7687-462b-aecb-bc75bd90b16d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cross_validation import KFold, cross_val_score\n",
        "cv_folds = KFold(n=df.shape[0], n_folds = 5, random_state = 42)\n",
        "cv_score = cross_val_score(tree, df_features, df_target, cv = cv_folds)\n",
        "print(\"{} +/- {:.2f}\".format(cv_score.mean(),cv_score.std() / 2))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
            "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8522727272727273 +/- 0.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LtUQvdimP89n",
        "colab_type": "code",
        "outputId": "7531c915-f20f-4508-aad0-89152e666af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "cell_type": "code",
      "source": [
        "#import sys\n",
        "#!{sys.executable} -m pip install sklearn\n",
        "\n",
        "'''from sklearn.decomposition import PCA\n",
        "# Make an instance of the Model\n",
        "pca = PCA(.95)\n",
        "pca.fit(x_train)\n",
        "print(pca.n_components_)\n",
        "x_train = pca.transform(x_train)\n",
        "x_test = pca.transform(x_test)'''\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators = 1000,criterion='entropy', random_state = 42, n_jobs =-1)\n",
        "\n",
        "rf_model=rf.fit(x_train,y_train)\n",
        "predictions=rf_model.predict(x_test)\n",
        "print(\"RandomForestClassifier\")\n",
        "print(\"Accuracy on training set: {:.3f}\".format(rf_model.score(x_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.3f}\".format(rf_model.score(x_test, y_test)))\n",
        "print(\"Feature importances:\\n{}\".format(rf_model.feature_importances_))\n",
        "print(\"f1_score: {:.3f}\".format(f1_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"precision_score: {:.3f}\".format(precision_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"recall_score: {:.3f}\".format(recall_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"classification_report:\\n {}\".format(classification_report(y_test,predictions, target_names=['<=50k','>50k'])))\n",
        "FPR, TPR, thresholds = precision_recall_curve(y_test, predictions, pos_label =1)\n",
        "print(\"AUC = \",auc(FPR, TPR))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier\n",
            "Accuracy on training set: 1.000\n",
            "Accuracy on test set: 0.858\n",
            "Feature importances:\n",
            "[0.15949781 0.04012221 0.17017344 0.03479404 0.07864075 0.0812495\n",
            " 0.06871847 0.09885796 0.01491441 0.01319362 0.10445289 0.03223744\n",
            " 0.08533917 0.01780831]\n",
            "f1_score: 0.853\n",
            "precision_score: 0.852\n",
            "recall_score: 0.858\n",
            "classification_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      <=50k       0.89      0.93      0.91      4957\n",
            "       >50k       0.74      0.62      0.68      1555\n",
            "\n",
            "avg / total       0.85      0.86      0.85      6512\n",
            "\n",
            "AUC =  0.4875653128630723\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WomEeJk6bvzg",
        "colab_type": "code",
        "outputId": "37b38202-41a9-4020-c098-e8b6bc961580",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(max_iter =100000,activation = 'relu',random_state=42, alpha=0.00000001)\n",
        "mlp.fit(x_train, y_train)\n",
        "predictions=mlp.predict(x_test)\n",
        "\n",
        "print(\"MLPClassifier \\n\")\n",
        "print(\"Accuracy on training set: {:.2f}\".format(mlp.score(x_train, y_train)))\n",
        "print(\"Accuracy on test set: {:.2f}\".format(mlp.score(x_test, y_test)))\n",
        "print(\"f1_score: {:.3f}\".format(f1_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"precision_score: {:.3f}\".format(precision_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"recall_score: {:.3f}\".format(recall_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"classification_report:\\n {}\".format(classification_report(y_test,predictions, target_names=['<=50k','>50k'])))\n",
        "FPR, TPR, thresholds = precision_recall_curve(y_test, predictions, pos_label =1)\n",
        "print(\"AUC = \",auc(FPR, TPR))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:912: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "MLPClassifier \n",
            "\n",
            "Accuracy on training set: 0.81\n",
            "Accuracy on test set: 0.80\n",
            "f1_score: 0.772\n",
            "precision_score: 0.785\n",
            "recall_score: 0.802\n",
            "classification_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      <=50k       0.82      0.96      0.88      4957\n",
            "       >50k       0.69      0.31      0.43      1555\n",
            "\n",
            "avg / total       0.78      0.80      0.77      6512\n",
            "\n",
            "AUC =  0.3424236911061186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X6UqCsTGmHe3",
        "colab_type": "code",
        "outputId": "24613258-f14e-4df5-c498-448cadaafa1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "from sklearn.feature_selection import RFE\n",
        "rfe = RFE(lr, 1)\n",
        "rfe = rfe.fit(x_train, y_train)\n",
        "print(rfe.support_)\n",
        "print(rfe.ranking_)\n",
        "print(\"Features sorted by their rank:\")\n",
        "feature_rank=sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), df_features.columns))\n",
        "print(feature_rank[:12])\n",
        "names=[]\n",
        "for rank, name in feature_rank[:13]:\n",
        "  names.append(name)\n",
        "lg1 = LogisticRegression(C=1000000).fit(x_train[names], y_train)\n",
        "predictions=lg1.predict(x_test[names])\n",
        "\n",
        "print(\"LogisticRegression with recursive feature elimination \\n\")\n",
        "print(\"Training Accuracy: {}\".format(lg1.score(x_train[names], y_train)))\n",
        "print(\"Test Accuracy: {}\".format(lg1.score(x_test[names], y_test)))\n",
        "print(\"f1_score: {:.3f}\".format(f1_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"precision_score: {:.3f}\".format(precision_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"recall_score: {:.3f}\".format(recall_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"classification_report:\\n {}\".format(classification_report(y_test,predictions, target_names=['<=50k','>50k'])))\n",
        "FPR, TPR, thresholds = precision_recall_curve(y_test, predictions, pos_label =1)\n",
        "print(\"AUC = \",auc(FPR, TPR))\n",
        "print(\"\\n LogisticRegression without recursive feature elimination \\n\")\n",
        "lg2 = LogisticRegression().fit(x_train, y_train)\n",
        "print(\"Training Accuracy: {}\".format(lg2.score(x_train, y_train)))\n",
        "print(\"Test Accuracy: {}\".format(lg2.score(x_test, y_test)))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[False False False False False False False False False  True False False\n",
            " False False]\n",
            "[ 6 10 14 11  2  3 12  4  5  1  9  8  7 13]\n",
            "Features sorted by their rank:\n",
            "[(1, 'sex'), (2, 'education-num'), (3, 'marital-status'), (4, 'relationship'), (5, 'race'), (6, 'age'), (7, 'hours-per-week'), (8, 'capital-loss'), (9, 'capital-gain'), (10, 'workclass'), (11, 'education'), (12, 'occupation')]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression with recursive feature elimination \n",
            "\n",
            "Training Accuracy: 0.8240939803439803\n",
            "Test Accuracy: 0.8220208845208845\n",
            "f1_score: 0.806\n",
            "precision_score: 0.810\n",
            "recall_score: 0.822\n",
            "classification_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      <=50k       0.84      0.94      0.89      4957\n",
            "       >50k       0.71      0.44      0.54      1555\n",
            "\n",
            "avg / total       0.81      0.82      0.81      6512\n",
            "\n",
            "AUC =  0.3997403477643068\n",
            "\n",
            " LogisticRegression without recursive feature elimination \n",
            "\n",
            "Training Accuracy: 0.8067030098280098\n",
            "Test Accuracy: 0.8060503685503686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qylebaair73t",
        "colab_type": "code",
        "outputId": "3e1fc3d7-be9b-40af-d6ef-6d69b68f01d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "clf.fit(x_train[names], y_train)\n",
        "predictions=clf.predict(x_test[names])\n",
        "print(\"svm  \\n\")\n",
        "print(\"Training Accuracy: {}\".format(clf.score(x_train[names], y_train)))\n",
        "print(\"Test Accuracy: {}\".format(clf.score(x_test[names], y_test)))\n",
        "print(\"f1_score: {:.3f}\".format(f1_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"precision_score: {:.3f}\".format(precision_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"recall_score: {:.3f}\".format(recall_score(y_test,predictions,average = \"weighted\")))\n",
        "print(\"classification_report:\\n {}\".format(classification_report(y_test,predictions, target_names=['<=50k','>50k'])))\n",
        "FPR, TPR, thresholds = precision_recall_curve(y_test, predictions, pos_label =1)\n",
        "print(\"AUC = \",auc(FPR, TPR))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "svm  \n",
            "\n",
            "Training Accuracy: 0.9197635135135135\n",
            "Test Accuracy: 0.8195638820638821\n",
            "f1_score: 0.798\n",
            "precision_score: 0.808\n",
            "recall_score: 0.820\n",
            "classification_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      <=50k       0.83      0.95      0.89      4957\n",
            "       >50k       0.73      0.39      0.51      1555\n",
            "\n",
            "avg / total       0.81      0.82      0.80      6512\n",
            "\n",
            "AUC =  0.39314392753551314\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}